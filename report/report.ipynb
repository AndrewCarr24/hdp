{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Hierarchical Dirichlet Processes in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By Andrew Carr and Eduardo Coronado\n",
    "##### STA 663, Duke University, Spring 2020\n",
    "##### April 30th, 2020\n",
    "</br> \n",
    "\n",
    "##### Github repo: https://github.com/datadiarist/hdp \n",
    "##### (installation instructions found on README)\n",
    "\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this report, we implement a Hierarchical Dirichlet Process (HDP) algorithm in Python based on Yee Why Teh et al's 2005 methods paper. The algorithm uses the Chinese Restaurant Franchise construction for its implementation. Further, code optimization was sought to improve the inference and text preprocessing speeds. Optimization tasks achieved a 30-40% reduction in run-time compared to initial versions of the algorithm. A set of 622 scientific paper abstracts were used infer topics with the HPD algorithm and performance was assessed via a perplexity score. Further, the algorithm was compared to existing package implementations in `gensim` and similar methods such as Latent Dirichlet Allocation (LDA).  Results from a comparison of perplexity scores indicate that our algorithm performs comparably well to Gensim's LDA when trained on an optimal number of topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following paper aims to describe the mathematical basis of Hierarchical Dirichlet Processes (HDPs) for topic modeling and its implementation in Python. This based on Yee Whye Teh et al’s 2005 methods paper carrying the same name and builds upon some methods described below.$^1$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Topic Modeling\n",
    "\n",
    "Before diving into details on HDP, it is helpful to provide some general background on topic modeling and related methods.  Topic modeling refers to the set of unsupervised techniques used to analyze text data in documents (corpus) and determine clusters of words (topics). These methods are commonly implemented in settings requiring grouping documents based on text similarity or exploring non-apparent trends in text data. For example, auto-tagging customer support tickets based the textual similarity to previous tickets or gathering underlying trends from open-ended questions in customer feedback that could inform product features. Therefore, common results from topic modeling include 1) a set of topics and 2) a set of documents grouped by topics. However, it is important to note that these methods treat text data in a bag-of-words representation which ignores syntactic and semantic information. Similarly, they require lots of high-quality data (i.e. pre-cleaned text) for them to be most effective. \n",
    "<br>\n",
    "\n",
    "To understand HPDs, it is important to start with a general understanding of base topic modeling algorithms such as Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA).$^{2,3}$ These methods have two main underlying assumptions when it comes to modeling text. The first is that similar topics will use similar words (i.e. each topic will have a distribution over words), and the second is that documents talk about multiple topics (i.e. document can be thought as a mixture of topics). However, there exists one main difference between LSA and LDA. LSA doesn’t assume topics are distributed according to a specific distribution, while LDA offers a probabilistic approach and assumes the topics are Dirichlet distributed. \n",
    "\n",
    "Below is a plate representation of an LDA model. Here $D$ is a set of documents and $N$ is the number of words within each document. The main idea is that for each document $d$ we have a set of topics ($\\theta_d$) and we assigns topics($z_{d,n}$) to those words ($w_{d,n}$). The parameter $\\alpha$ controls how many topics are assigned to documents, while $\\eta$ controls how many words are assigned to topic\n",
    "\n",
    "<figure>\n",
    "    <img src=\"imgs/lda_plate.png\" alt=\"Drawing\" style=\"display: block;margin-left: auto;margin-right: auto;width: 50%;\"/>\n",
    "    <figcaption style=\"text-align: center;\">LDA plate model. <i> Source: D. Blei (Columbia, 2012)</i></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the main disadvantage of either of these models is their parametric nature, that is, that the number of clusters (i.e. mixture components) has to be defined. As a result, non-parametric methods such as Dirichlet Process Mixtures were developed to overcome this limitation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Dirichlet Process Mixtures\n",
    "\n",
    "Dirichlet Process Mixtures (DPMs) can be thought of as an extension to LDA in that, instead of predefining topics, these are inferred from the data (non-parametric) and can be thought as coming from an infinite distribution of topics. This last statement is only possible due thanks to something called Dirichlet Processes (DPs). \n",
    "\n",
    "#### Dirichlet Processes (DPs)\n",
    "\n",
    "Formally, a DP is defined as a distribution over distributions and is made up of a countably infinite number of point masses.\n",
    "\n",
    "In simpler terms, this generates a discrete distribution that is considered \"infinite\". This infinitely discrete property arises from first generating samples from a continuous base distribution (e.g. a Gaussian), which can take an infinite number of forms, before these are realized as discrete when we assign weights to these samples. The result is an infinitely discrete distribution that follows a Dirichlet distribution.\n",
    "\n",
    "For example, the diagram below shows $G$ (light blue) samples generated via a Dirichlet Process with parameters $\\alpha$ (think about this as weights) and $G_0$ (a continuous base distribution, e.g. a Gaussian). In other words, the $G$ is made up of \"countably infinite\" samples generated from weighted Gaussian samples from $G_0$ (red) and weights defined by $\\alpha$.\n",
    "<br><br>\n",
    "\n",
    "<figure>\n",
    "    <img src=\"imgs/dp.png\" alt=\"Drawing\" style=\"display: block;margin-left: auto;margin-right: auto;width: 65%;\"/>\n",
    "    <figcaption style=\"text-align: center;\">Dirichlet Process representation. <i> Source: K. El-Arini (2008)</i></figcaption>\n",
    "</figure>\n",
    "<br>\n",
    "\n",
    "In topic modeling the Dirichlet Process is used to generate an infinite discrete distribution of topics. \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dirichlet Process Mixtures (DPMs)\n",
    "\n",
    "A common, and sometimes helpful analogy, to DPMs is that of a Chinese Restaurant Process. We imagine a restaurant that serves dishes (topics) from an infinite menu (set of topics) and has space for infinite tables (word clusters). Each table can only be served one dish from the menu, but dishes can be repeated among tables. Customers (words) are then seated with certain probability on either an occupied or a new table. The diagram below shows a depiction of this process. The parameter $\\phi_{k,t}$ on each table represents a topic-table ($k,t$ are topic and table indexes), and the customers represent the words. When a new customer (word) appears, it seated in either on a new or existing table. These decision are based on probabilities proportional to number of seated customers per table ($N$), overall customers seated, and the concentration parameter $\\alpha$. \n",
    "\n",
    "\n",
    "<figure>\n",
    "    <img src=\"imgs/crp.png\" alt=\"Drawing\" style=\"display: block;margin-left: auto;margin-right: auto;width: 50%;\"/>\n",
    "    <figcaption style=\"text-align: center;\">Chinese Restaurant Process. <i> Source: Eric P. Xing (2014)</i></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process is complete once all customers are seated (i.e. all words have been assigned to a cluster) and we can interpret the topics from the words in clusters sharing the topic (dish).\n",
    "\n",
    "But what if we had multiple document collections (groups) – say a group on statistics and another one on computer engineering - and wanted these groups to share information/topics in our model? The current set-up wouldn’t allow for these collections to share the same infinite number of topics given each DP would generate an independent mixture for each corpora. Here’s where the hierarchical property of HDP comes into play.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Hierarchical Dirichlet Process (HDP)\n",
    "\n",
    "As its name states HDPs builds upon DPMs using a hierarchy, in that, they provide an infinite number of topics that can now be shared amongst different corpora (document groups). For a quick comparison, the images below depict the differences between DPMs and HDPs. First, the DPMs diagram below shows how although two groups sample from the same continuous base distribution $H$ (left), they don't share the same Dirichlet Process distribution (right) with infinite number of topics.\n",
    "\n",
    "\n",
    "<figure>\n",
    "    <img src=\"imgs/DPM_2.png\" alt=\"Drawing\" style=\"display: block;margin-left: auto;margin-right: auto;width: 70%;\"/>\n",
    "    <figcaption style=\"text-align: center; padding-left:10%; padding-right:10%;\"> <b>Dirichlet Process Mixtures</b>: (left) plate diagram representing DPM for two sets of documents, (right) samples from distinct DPM for each group. <i> Source: Teh et al (2007)</i></figcaption>\n",
    "</figure>\n",
    "\n",
    "<br><br>\n",
    "In comparison, the HDP diagram below shows how introducing a hierarchy allows both groups to sample from the same Dirichlet Process distribution with infinite topics (here noted as $G_0$).\n",
    "\n",
    "\n",
    "<figure>\n",
    "    <img src=\"imgs/HDP_2.png\" alt=\"Drawing\" style=\"display: block;margin-left: auto;margin-right: auto;width: 70%;\"/>\n",
    "    <figcaption style=\"text-align: center; padding-left:10%; padding-right:10%;\"> <b>Hierarchical Dirichlet Process </b>: (left) plate diagram representing HDP for two sets of documents now sharing an infinite number of topics $G_0$, (right) samples from shared $G_0$ for each group. <i> Source: Teh et al (2007)</i></figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can continue with the Chinese Restaurant Process analogy and represent HDPs as a Chinese Restaurant Franchise. The only difference will be that there are multiple restaurants (document groups) that now share dishes from one global infinite menu ($G_0$). The process is similar to that of the Chinese Restaurant Process in that once words have been assigned to a cluster and we can interpret the topics. However, this time these topics are shared amongs topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm presented in this paper implements a Hierarchical Dirichlet Process to infer topics from a set of documents using a Chinese Restaurant Franchise scheme given this representation allows for straightforward Gibbs (MCMC) sampler.\n",
    "\n",
    "First, given text data as input, some preprocessing steps are used to extract a common vocabulary and relevant words to each document. These include word stemming, tokenization, stop word removal and frequency filtering.\n",
    "Next, the Chinese Restaurant Franchise framework is used to infer the topics shared across documents. These are then interpreted from words grouped in each topic cluster. \n",
    "\n",
    "At a high-level the process involves the following:\n",
    "1. looping through each document,\n",
    "2. looping through each word in a document, and \n",
    "3. probabilistically assigning these words to a topic cluster\n",
    "\n",
    "\n",
    "This process is repeated for multiple epochs (1 epoch = 1 loop through all documents) to gain some convergence on the words in each cluster. The topics can then be interpreted based on the words within each topic cluster\n",
    "The processes described are explained in detail below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Pre-processing\n",
    "\n",
    "Given a set of document text data in a single-column CSV, each observation (i.e. row) was preprocessed using the following five steps:\n",
    "\n",
    "1. Remove punctuations and lemmatize words to return the dictionary format of each word\n",
    "2. Remove stopwords and short words (i.e. length <= 3)\n",
    "3. Build a term-frequency (tf) matrix based on the aggregate vocabulary (i.e. all unique words in all documents)\n",
    "4. Filter out low and high frequency words (i.e. those appearing in either < 3 documents or more than half of the documents)\n",
    "5. Assign a unique word identified and build a nested list, where each document is a sublist with unique word identifiers representing the words in that document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Inference\n",
    "\n",
    "As described at a high-level the Background section, HDPs can be represented via a Chinese Restaurant Franchise metaphor. Now, to be more specific, restaurants correspond to document groups $j$ and customers/words $i$ correspond to factors $\\theta_{ji}$. Topics from the global menu are denoted by $K$ iid random variables $\\phi_1,…,\\phi_K$, and $\\psi_{jt}$ represent a table-specific topic choice at table $t$ in document $j$.\n",
    "\n",
    "It is important to know that there is a specific correspondence between the $\\theta$s, $\\psi$s, and $\\phi$s; specifically, each $\\theta_{ji}$ is associated with one $\\psi_{jt}$ and one $\\psi_{jt}$ is associated with one $\\phi_k$ as shown in the diagram below.\n",
    "<br> <br>\n",
    "\n",
    "<figure>\n",
    "    <img src=\"imgs/crp_teh.png\" alt=\"Drawing\" style=\"display: block;margin-left: auto;margin-right: auto;width: 40%;\"/>\n",
    "    <figcaption style=\"text-align: center; padding-left:10%; padding-right:10%;\"> <b>Chinese Restaurant Franchise</b>: Rectangles represent the restaurants and the circles the tables in each restaurant. Customers are represented as $\\theta_{ji}$ and seated on a table with a $\\psi_{jt}$ (table-specific topic choice) which is defined by $\\phi_k$ <i> Source: Teh et al (2006)</i></figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "However, we can simplify these associations using indexes. Let $t_{ji}$ be the index associating the $\\theta_{ji}$ and $\\psi_{jt}$, and $k_{jt}$ be the index associating the $\\psi_{jt}$ and $\\phi_k$. Thus, in the metaphor customer $i$ in restaurant $j$ sits at table $t_{ji}$  and table $t$ in restaurant $j$ serves dish/topic $k_{jt}$.\n",
    "\n",
    "Without these indexes, the MCMC would need to infer $\\theta_{ji}$s and $\\psi_{jt}$s from their respective posterior distributions. \n",
    "\n",
    "Instead, the simplified representation makes the MCMC sampling for efficient while keeping properties from the original associations needed to infer the topics. Now, we sample the index variables $t_{ji}$ and $k_{jt}$ using adapted versions of the $\\theta_{ji}$ and $\\psi_{jt}$ posteriors.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Sampling pseudocode\n",
    "\n",
    "The following pseudocode provides a general overview of the sampling steps. Before, diving into the specifics of each sampling step additional notation will be provided within the metaphor within the franchise metaphor.\n",
    "\n",
    "<figure>\n",
    "    <img src=\"imgs/pseudo-code.png\" alt=\"Drawing\" style=\"display: block;margin-left: auto;margin-right: auto;width: 60%;\"/>\n",
    "</figure>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Relevant Notation\n",
    "\n",
    "Let $j$ index the restaurant (document), $i$ index the customer (word), $k$  index the dish (topic), and $t$ index the table. Let $n$ denote customer-related counts and $m$ table-related counts, and marginal counts be represented with dots. \n",
    "\n",
    "Thus, $n_{jtk}$ is the number of customers in restaurant $j$ at table $t$ eating dish $k$, and $n_{jt\\cdot}$ is the overall number of customers in restaurant $j$ at table $t$.\n",
    "\n",
    "In terms of table-related counts, $m_{jk}$ denotes the number of tables in restaurant $j$ serving dish $k$, and thus $m_{j\\cdot}$ is the number of tables in restaurant $j$, $m_{\\cdot k}$ is the number of overall tables serving dish $k$ and $m_{\\cdot \\cdot}$ be the number of overall occupied tables.\n",
    "\n",
    "We use boldface variables to represent sets. \n",
    "For example $\\mathbf{x}_{jt}$ = ( $x_{ji}$: all $i$ with $t_{ji} = t$), $\\mathbf{t}$ = ($t_{ji}$: all $j,i$), and $\\mathbf{k}$ = ($k_{jt}$: all $j,t$).Let $\\mathbf{x}$ represent the observed data, and $x_{ji}$ be the $i$ observation/customer in restaurant $j$.  \n",
    "\n",
    "Superscripts attached to variables or counts means the variable removed from the set or count (e.g. $x^{-ji} = \\mathbf{x} \\setminus x_{ji}$). As an example $n_{jt\\cdot}^{-ji}$ is the number of customers in restaurant $j$ seated in table $t$ excluding customer $x_{ji}$.\n",
    "\n",
    "Given this notation, we now move to the specifics of sampling the indexes $\\mathbf{t}$ and $\\mathbf{k}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Sampling <b>t</b>\n",
    "    \n",
    "For each word $x_{ji}$, we first construct a set of posterior probabilities using the conditional posterior of $t_{ji}$ that combines the prior distribution of $t_{ji}$ and the likelihood of generating $x_{ji}$ with the following piecewise function\n",
    "    \n",
    "$$p(t_{ji} = t \\mid \\textbf{t}^{-ji}, \\textbf{k}) =   \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      n_{jt \\cdot}^{-ji}\\; f_{k_{jt}}^{-x_{ji}}(x_{ji}) & \\text{if } t \\text{  previously used} \\\\\n",
    "      \\alpha_0\\; p(x_{ji} \\mid \\textbf{t}^{-ji}, t_{ji} = t^{new}, \\textbf{k}) & \\text{if } t = t^{new} \\\\\n",
    "\\end{array} \n",
    "\\right.$$\n",
    "    \n",
    "which then are used to obtain a posterior sample of $t$ from a categorical distribution. \n",
    "    \n",
    "<u><b>Intuitively</b></u>, we sample a new table  index with a probability proportional to $\\alpha_0$ or a previously used one based on the number of $x$'s already assigned to that table.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Specifically,  <b>for a previously used</b> $t$ the likelihood  $f_{k}^{-x_{ji}}(x_{ji})$ is generated from  conditional density of observation $x_{ji}$ under mixture component $k$ given all other observations except $x_{ji}$ and formally defined as\n",
    "\n",
    "$$f_{k}^{-x_{ji}}(x_{ji}) = \\frac{\\int f(x_{ji} \\mid \\phi_k) \\prod_{j'i' \\neq ji, z_{j'i'} = k}f(x_{j'i'}\\mid\\phi_k)h(\\phi_k) d\\phi_k }{\\int \\prod_{j'i' \\neq ji, z_{j'i'} = k}f(x_{j'i'}\\mid\\phi_k)h(\\phi_k) d\\phi_k }$$\n",
    "\n",
    "with the sampling $f(\\cdot \\mid \\phi_k)$ and prior  $h(\\cdot)$ being conjugated as follows - $h(\\cdot) \\sim Dir(0.5)$ a symmetric Dirichlet and $f(\\cdot \\mid \\phi_k) \\sim Cat(\\mathbf{\\phi})$ a categorical distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>For a  new t </b> ($t = t^{new}$) the likelihood is generated via $p(x_{ji} \\mid \\textbf{t}^{-ji}, t_{ji} = t^{new}, \\textbf{k})$ where we integrate out the possible values of $k_{jt^{new}}$ and then multiplied by the document group the concentration parameter $\\alpha_0$ which defines the number of topics per document\n",
    "\n",
    "$$p(x_{ji} \\mid \\textbf{t}^{-ji}, t_{ji} = t^{new}, \\textbf{k}) = \\sum_{k=1}^K \\frac{m_{\\cdot k}}{m_{\\cdot\\cdot} + \\gamma} f_{k}^{-x_{ji}}(x_{ji}) + \\frac{\\gamma}{m_{\\cdot\\cdot} + \\gamma} f_{k^{new}}^{-x_{ji}}(x_{ji}) $$\n",
    "\n",
    "where $f_{k^{new}}^{-x_{ji}}(x_{ji}) = \\int f(x_{ji} \\mid \\phi) h(\\phi) d\\phi $ is the prior density of $x_{ji}$ and $\\gamma$ is the topic concentration parameter of the base distribution H."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Now, if the sampled $t$ is <u> NEW </u> </b> then we must find wheter this new table index ($t^{new}$) should be associated with either an existing topic or a new topic ($k_{jt^{new}})$. Thus, we construct the posterior probabilities of $k_{jt^{new}}$ using the following piecewise function and then sample a new value of $k$ from a categorical distribution.\n",
    "\n",
    "$$p(k_{jt^{new}} = k \\mid \\textbf{t},\\textbf{k}^{-jt^{new}}) =   \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      m_{\\cdot k}\\; f_{k_{jt}}^{-x_{ji}}(x_{ji}) & \\text{if } k \\text{  previously used} \\\\\n",
    "      \\gamma\\; f_{k^{new}}^{-x_{ji}}(x_{ji}) & \\text{if } k = k^{new} \\\\\n",
    "\\end{array} \n",
    "\\right.$$\n",
    "\n",
    "with $f_{k^{new}}^{-x_{ji}}(x_{ji}$ and $\\gamma$ having the same definitions as before.\n",
    "\n",
    "<u><b>Intuitively</b></u>, we sample a new table topic index with a probability proportional to $\\gamma$ or a previously used one based on the number of tables already associated with that topic.\n",
    "<br>\n",
    "\n",
    "As a result of updating $t_{ji}$ some table might become unoccupied $n_{jt\\cdot}$, so it is removed because there is a probability 0 that this table will be occupied in the future.  We delete a specific table-topic component $k_{jt}$ as a consequence of deleting this table $t$, which in turn might leave a topic component $k$ unallocated. If that is the case, this component $k$ is deleted as well.\n",
    "<br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Sampling <b>k</b>\n",
    "\n",
    "For each table in document $j$, we sample a new table topic $k_{jt}$ from a categorical distribution based on the posterior probabilities generated from the following piecewise function. \n",
    "\n",
    "$$p(k_{jt^{new}} = k \\mid \\textbf{t},\\textbf{k}^{-jt}) =   \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      m_{\\cdot k}\\; f_{k_{jt}}^{-\\textbf{x}_{ji}}(\\textbf{x}_{ji}) & \\text{if } k \\text{  previously used} \\\\\n",
    "      \\gamma\\; f_{k^{new}}^{-\\textbf{x}_{ji}}(\\textbf{x}_{ji}) & \\text{if } k = k^{new} \\\\\n",
    "\\end{array} \n",
    "\\right.$$\n",
    "\n",
    "\n",
    "Since changing $k_{jt}$ changes the associations of all data items $x{ji}$ in that table, we slightly modify the likelihood $f_{k}^{-x_{ji}}(x_{ji})$ as follows - replace $x_{ji}$ with $\\mathbf{x}_{jt}$ given we want to condition based all data related to that topic except the ones in table $t$.\n",
    "\n",
    "The intuition is similar to that of sampling a new topic in the previous section, but now considers a larger range of data points when computing the posterior probabilities. Again, if updating any table-topic component $k_{jt}$ leaves a topic component $k$ unallocated then this component is deleted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "Data preprocessing and HDP inference scripts were initially developed using plain python to understand what would be the baseline performance of the scripts without any optimizations. This code was stored separately in two python scripts named `text_prep.py` and `HDP_baseline.py`. \n",
    "\n",
    "To understand the bottlenecks of our code we timed and profiled each script using a test set composed of 622 paper abstracts. Various methods were used including magics such as `timeit` and `prune`, and the `cython` profiler to understand which areas could turned into C++ code. The average run-time speed for the `text_prep.py` script was about 2.5 seconds, while the inference script `HDP_baseline.py` was 2.6 seconds on  Mac OS (4CPUs, 16 Gb RAM).\n",
    "\n",
    "#### Optimizing `text_prep.py`\n",
    "\n",
    "The script's goals was to preprocess the abstract text data and produce a data structure ready-to-use for the inference functions as described on the previous section. The output structure would be a set of lists, each for a document, containing the words from the shared vocabulary appearing on each document. To simplify the inference, words from the vocabulary were coded with unique ids. \n",
    "\n",
    "After profiling the script, most time was spent on the lemmatization and stemming steps using the `nltk` package, followed by the word frequency and filtering processes to generate the shared vocabulary and inference-ready data structure. Given the steps for lemmatization/stemming are involved and the `nltk` package provides easy-to-use methods, we focused our optimization on the second most time consuming processing - constructing word frequencies, filtering and generating the data objects required for inference.\n",
    "\n",
    "These processes were optimized with custom C++ code `hdp_preproc.cpp` that leveraged `STL` containers and `Eigen` C++ library, and used `pybind11` to wrap it for Python use. We first optimized the word frequency and filtering methods, followed by some optimizations on text preprocessing steps (e.g. removing punctuations). \n",
    "\n",
    "The custom functions were tested and the profiled to understand the performance gain. <b>On average these optimizations reduced the text preprocessing time by 30% compared to the straightforward script</b>  as seen below. The optimized script was stored as `text_prep_optim.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('eigen'):\n",
    "    ! git clone  https://gitlab.com/libeigen/eigen.git\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import text_prep\n",
    "import text_prep_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.66 s ± 277 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r3 -n3 text_prep.run_preprocess(\"../data/tm_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.95 s ± 60.1 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r3 -n3 text_prep_optim.run_preprocess_optim(\"../data/tm_test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing `HDP_baseline.py`\n",
    "\n",
    "This script implements the pseudo-code presented on the previous section and outputs inferences on topics, counts and words groupings found in the input text data. After profiling the script, most of the time was spent sampling from the posterior distributions for both `k` and `t` as well as obtaining posterior multinomial random samples. \n",
    "\n",
    "Therefore, we first optimized the `sample_t` and `sample_k` functions using C++ custom code `hdp_funcs.cpp`. These again leveraged `STL` containers and the `Eigen` to improve speeds. The largest increase in speed came from the `sample_k` function since it required to computes the explicit posterior for a Dirichlet-Multinomial distribution. Similarly, the `numpy` multinomial random sampling was optimized with custom C++ code based on a conditional binomial sampling method referenced in the `GNU` scientific library package.\n",
    "\n",
    "Overall, <b>these optimizations reduced the inference run-time by 40% on average </b> compared to the straighforward python script as shown below. The optimized script was stored as `HDP_optimized.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import HDP_baseline\n",
    "import HDP_optimized\n",
    "import numpy as np\n",
    "\n",
    "vocab, docs = text_prep_optim.run_preprocess_optim(\"../data/tm_test_data.csv\")\n",
    "\n",
    "# Hyper params\n",
    "np.random.seed(7)\n",
    "beta = 0.5 # word concentration (LDA)\n",
    "alpha = 0.8 # GP hyperparam (tuned, can use np.random.gamma(1,1) alternatively)\n",
    "gamma = 10 # Base GP hyperparam (tuned, can use np.random.gamma(1,1) alternatively)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.74 s ± 69.4 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r3 -n3 HDP_baseline.hdp(docs, vocab, gamma, alpha, beta, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.42 s ± 56.5 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r3 -n3 HDP_optimized.hdp_optimized(docs, vocab, gamma, alpha, beta, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation - Testing on real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One popular way to evaluate the fit of a topic model, both for hierarchical topic models and for standard topic models where the number of topics is set as a hyperparameter, is by measuring the perplexity of the model on a given data set.  Topic model perplexity evaluates the fit of a model using two distributions returned by the model: the distribution of words across topics and the distribution of topics within documents.  Namely, if the likelihood of a word being assigned to a given topic is high, and the probability that that topic will appear within a document is also high, this will improve the fit of the model according to the perplexity metric.  Perplexity is positive number that indicates better fit through smaller values and is defined by the following equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P = \\frac{-\\sum_{i=1}^{M} \\log p(w)}{N}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this equation, $M$ denotes the number of documents in the corpus, $p(w)$ is a probability distribution produced from the document-topic and word-topic distributions, and $N$ is the total numbber of terms across documents.  We created our own function to measure topic model perplexity, perplex_func, which is called from the perplexity script in the code below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gensim package offers a broad range of tools for topic modeling.  We ran Gensim's topic model on real data: a set of 622 abstracts from several math and science journals.  This dataset has been used in the past in R topic modeling package vignettes, so our expectation is that Gensim will find distinct topics in the data.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we modified the corpus and vocabulary so that they are in a format that is compatible is Gensim. This entailed converting the numeric document index back into strings and applying functions from Gensim's Dictionary module to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import perplexity\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.test.utils import common_corpus\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Create list of words in each document from doc index and vocabulary\n",
    "docs_words = perplexity.back_to_words(docs, vocab)\n",
    "\n",
    "# Create a formatted corpus and dictionary from a list of texts\n",
    "common_dictionary = Dictionary(docs_words)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in docs_words]\n",
    "\n",
    "# Manual corpus key (for ensuring that document-word indices match vocab key)\n",
    "corpus_key = []\n",
    "for i in common_corpus:\n",
    "    corpus_key.append([j[0] for j in i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we trained 15 standard, non-hierarchical topic models on the data.  For each model, the number of topics (a hyperparameter in standard LDA) was set between 1 and 15.  The output of each model was then converted to a set of word-topic and document-topic distributions using the model_to_dist function from the perplexity script.  We used these distributions to compute the perplexity of the models with varying numbers of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing perplexity scores for Gensim's LDA fitted with varying numbers of topics  \n",
    "perplex_lst = []\n",
    "for i in range(1,15):\n",
    "    topic_num = i\n",
    "    lda = LdaModel(common_corpus, num_topics=topic_num)\n",
    "    doc_topic_dist, word_topic_dist = perplexity.model_to_dist(lda, common_corpus, common_dictionary, topic_num)\n",
    "    perp = perplexity.perplex_func(doc_topic_dist, word_topic_dist, corpus_key)\n",
    "    perplex_lst.append((i,perp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot()\n",
    "ax1.set_ylabel('Perplexity')\n",
    "ax1.set_xlabel('K')\n",
    "\n",
    "plt.plot([i[0] for i in perplex_lst], [i[1] for i in perplex_lst])\n",
    "plt.scatter([j[0] for j in perplex_lst if j[1] == min([i[1] for i in perplex_lst])], \n",
    "            min([i[1] for i in perplex_lst]), c = 'r')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above displays the relationship between the perplexity score of each model and the number of topics hyperparameter given to that model.  We tried using random.seed to ensure that the models produced consistent results.  However, we found that model output for both Gensim's LDA and our algorithm varied even with random seeding.  The figure above will therefore vary slightly every time this notebook is run.  The model with best fit (i.e. minimum perplexity) generally has been 10 and 14 topics and a perplexity score of about 675.  Scores ranged between 675 and 830.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical LDA with HDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run our hierarchical LDA algorithm on the same data and use the functions from the perplexity module to evaluate the performance of our algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we ran the algorithm several times, varying each model by the number of epochs used to train the model.  We converted the output of our algorithm to data structures that our perplexity function can accommodate and stored word-topic and document-topic distributions in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "dist_stuff = []\n",
    "\n",
    "for i in range(1, 10):\n",
    "\n",
    "    # Running HDP with varying numbers of iterations\n",
    "    doc_arrays, topic_idx, n_kv, m_k = HDP_optimized.hdp_optimized(docs, vocab, gamma, alpha, beta, epochs=i)\n",
    "\n",
    "    doc_dist = perplexity.doc_arrays_to_doc_topic_distribution(doc_arrays, topic_idx)\n",
    "    word_dist = perplexity.n_kv_to_word_dist(n_kv, topic_idx)\n",
    "    \n",
    "    # Storing distributions in list\n",
    "    dist_stuff.append((doc_dist, word_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we computed perplexity of the model train on 1 to 9 epochs and stored these perplexity scores.  We plotted the relationship between perplexity and number of iterations below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplex_hdp = []\n",
    "for i in range(9):\n",
    "    perplex_hdp.append(perplexity.perplex_func(dist_stuff[i][0], dist_stuff[i][1], docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZRU9Zn/8ffTO92sTTcF0kCzNEu74NIxuC9QipOMOibO6JholgnGMFFjojG/+c3xzMwvOVFj4hiNE1yimRidxOhoZozQIG5JQMGFIGuLbM3W7EtDr8/vj7oNBYLV3VT1ra7+vM6pU/d+61bdR4T61N2ea+6OiIjIJ8kKuwAREUl/CgsREUlIYSEiIgkpLEREJCGFhYiIJJQTdgGpUFJS4uXl5WGXISLSrSxcuHCru5ce7bWMDIvy8nIWLFgQdhkiIt2Kma051mvaDSUiIgkpLEREJCGFhYiIJKSwEBGRhBQWIiKSkMJCREQSUliIiEhCCos4O+sbuX/2CpZs2B12KSIiaSUjL8rrLDPjwVdqONDUSuUJfcMuR0QkbWjLIk6/Xrl8elQx1Us2hV2KiEhaUVgcITohwod1+1hVtzfsUkRE0obC4ghTKiMAVC/ZHHIlIiLpI2VhYWaPm9kWM1scN3a1mX1gZq1mVnXE8t8zsxozW25ml8aNTw3GaszszlTV26ZsQCGVQ/oqLERE4qRyy+IJYOoRY4uBq4DX4wfNrBK4BjgxeM/PzCzbzLKBh4DLgErg2mDZlIpWRli4dgdb9zakelUiIt1CysLC3V8Hth8xttTdlx9l8SuAZ9y9wd0/AmqAM4NHjbuvcvdG4Jlg2ZSKVkZwh1eWbkn1qkREuoV0OWYxFFgXN78+GDvW+MeY2TQzW2BmC+rq6o6rmBNP6MvQ/r2YpV1RIiJA+oTFcXP3Ge5e5e5VpaVHvdFTu5kZUyYM4s2aOvY3tiSpQhGR7itdwqIWGBY3XxaMHWs85aKVgznQ1MqbNVu7YnUiImktXcLiReAaM8s3s5FABfAW8DZQYWYjzSyP2EHwF7uioE+PKqZPQY4u0BMRIYXtPszsaeBCoMTM1gN3ETvg/VOgFPhfM3vP3S919w/M7DfAEqAZmO7uLcHn/CMwE8gGHnf3D1JVc7zc7CwuGjeIOUu30NLqZGdZV6xWRCQtpSws3P3aY7z0/DGW/z7w/aOMvwS8lMTS2m1KZYQX39/Au2t3UFVeHEYJIiJpIV12Q6WlC8eVkpttukBPRHo8hcUn6FuQy6RRAxUWItLjKSwSiFZGWLV1HzVb1FhQRHouhUUCUyaosaCIiMIigRP69+KkoX11Cq2I9GgKi3aIThjMu+t2UrdHjQVFpGdSWLRDW2PBOUu1K0pEeiaFRTtMGNKHof17MVthISI9lMKiHcyMaGWEN1Zupb6xOexyRES6nMKinS6pjNDQ3MobK9VYUER6HoVFO31qZDF9C3J0Cq2I9EgKi3bKzc7iovGDeGVZrLGgiEhPorDogGhlhO37Glm4ZkfYpYiIdCmFRQdcMLatsaAu0BORnkVh0QF9CnI5a3QJ1Us2465dUSLScygsOihaGWH1tno1FhSRHkVh0UHRoLHgLJ0VJSI9iMKigwb3K+CUsn46hVZEehSFRSdEJ0R4b91Otuw5EHYpIiJdQmHRCdETY7ui5izdEnIlIiJdQ2HRCeMifRhW3Eu7okSkx1BYdIKZMWVChDdrtrKvQY0FRSTzKSw6KVoZobG5lTdW1oVdiohIyiksOunM8mL69crVKbQi0iMoLDopJzuLi4PGgs0trWGXIyKSUikLCzN73My2mNniuLFiM6s2s5XB84Bg3MzsATOrMbNFZnZ63HtuCJZfaWY3pKrezohWRthZ38QCNRYUkQyXyi2LJ4CpR4zdCcxx9wpgTjAPcBlQETymAQ9DLFyAu4BPA2cCd7UFTDo4f2wpedlZOitKRDJeysLC3V8Hth8xfAXwZDD9JHBl3PgvPWYe0N/MhgCXAtXuvt3ddwDVfDyAQtM7P4ezxwxUY0ERyXhdfcwi4u4bg+lNQCSYHgqsi1tufTB2rPGPMbNpZrbAzBbU1XXdGUrRyghrt9ezYrMaC4pI5grtALfHfoon7ee4u89w9yp3ryotLU3WxyY0JWgsOHupdkWJSObq6rDYHOxeInhu65dRCwyLW64sGDvWeNqI9C1g4rD+OoVWRDJaV4fFi0DbGU03AC/EjV8fnBU1CdgV7K6aCVxiZgOCA9uXBGNp5ZLKCO+v28nm3WosKCKZKZWnzj4N/BkYZ2brzeyrwA+BqJmtBKYE8wAvAauAGuAR4BsA7r4d+Dfg7eDxr8FYWolWaleUiGS2nFR9sLtfe4yXJh9lWQemH+NzHgceT2JpSVcxqDfDiwupXrKZ6z49IuxyRESSTldwJ4GZEa2M8KeabexVY0ERyUAKiySJVkZobGnl9RVqLCgimUdhkSRVIwbQvzBXV3OLSEZSWCRJfGPBJjUWFJEMo7BIoksqI+za38Tbq9PuhC0RkeOisEii8ypKyctRY0ERyTwKiyQqys/h3DElaiwoIhlHYZFk0coI63fsZ/nmPWGXIiKSNAqLJJs8YRBmUP2BdkWJSOZQWCTZoD4FnDqsP9Vq/SEiGURhkQJTJkRYtH4Xm3apsaCIZAaFRQpcEjQW1NaFiGQKhUUKjBnUm/KBhTqFVkQyhsIiBdoaC/75w63sOdAUdjkiIsdNYZEi0crBNLU4r6mxoIhkAIVFipwxYgDFRXnaFSUiGUFhkSLZWcbF4wcxV40FRSQDKCxSKFoZYfeBZt76SI0FRaR7U1ik0HkVJeSrsaCIZACFRQoV5uVwXoUaC4pI96ewSLFoZYTanftZulGNBUWk+1JYpNjF4yOxxoLaFSUi3ZjCIsVK++Rz2rD+VC/dFHYpIiKdprDoAtHKwSyu3c2GnfvDLkVEpFMUFl0gGjQWnK3GgiLSTYUSFmZ2i5ktNrMPzOzWYKzYzKrNbGXwPCAYNzN7wMxqzGyRmZ0eRs3HY8yg3owqKdJxCxHptro8LMzsJOBrwJnAROCzZjYGuBOY4+4VwJxgHuAyoCJ4TAMe7uqakyFaGWHeqm3sVmNBEemGwtiymADMd/d6d28GXgOuAq4AngyWeRK4Mpi+Avilx8wD+pvZkK4u+nhFKyM0tTivLldjQRHpfsIIi8XAeWY20MwKgb8ChgERd98YLLMJiATTQ4F1ce9fH4wdxsymmdkCM1tQV5d+X8inDR/AQDUWFJFuqsvDwt2XAncDs4CXgfeAliOWcaBDlzy7+wx3r3L3qtLS0mSVmzTZWcbkCYN4dfkWGpvVWFBEupd2hYWZ3WdmJyZrpe7+mLuf4e7nAzuAFcDmtt1LwfOWYPFaYlsebcqCsW4nWjmYPWosKCLdUHu3LJYCM8xsvpl93cz6Hc9KzWxQ8Dyc2PGKXwMvAjcEi9wAvBBMvwhcH5wVNQnYFbe7qls5d0wJBblZVC/RBXoi0r20Kyzc/VF3Pwe4HigHFpnZr83sok6u93dmtgT4PTDd3XcCPwSiZrYSmBLMA7wErAJqgEeAb3RynaHrlZfNuWNK1VhQRLqdnPYuaGbZwPjgsRV4H7jNzG5092s6slJ3P+8oY9uAyUcZd2B6Rz4/nV1SGWH20s18sGE3Jw09rg00EZEu095jFj8BlhE7c+kHwfGGu939r4HTUllgprl4wiA1FhSRbqe9xywWAae6+43u/tYRr52Z5JoyWknvfM4YPkBhISLdSnvD4gvuvi9+wMzmALj7rqRXleGilRGWbNzN+h31YZciItIunxgWZlZgZsVAiZkNCPo3FZtZOUe5ME7a52BjQW1diEg3kWjL4kZgIbGD2u8E0wuJndb6YGpLy1yjSnszurSIanWhFZFu4hPDwt3/3d1HAt9x95Fxj4nurrA4DtHKwcxftZ1d+9VYUETSX6LdUBcHk7VmdtWRjy6oL2NFKyM0tzqvLt+SeGERkZAlus7iAuAV4K+P8poDzyW9oh7itGH9KemdT/WSzVxxqg7/iEh6+8SwcPe7gucvd005PUdWljFlwiD+d9FGGptbycvRTQtFJH2196K8/4zvB2VmI9pOnZXOmzIhwp6GZuat2hZ2KSIin6i9P2ffBOab2V+Z2deAauD+1JXVM5xbUUKv3GxdoCciaa+9jQR/DvwDsVNm/xU4391/n8rCeoKC3GzOqyhh9lI1FhSR9Nbe3VBfBB4n1nX2CeAlM5uYwrp6jGhlhI27DrC4dnfYpYiIHFN7d0N9DjjX3Z929+8BX+fQ/bLlOEyeECHL0D0uRCSttXc31JXuviVu/i3UQDApiovyqBpRzCwdtxCRNNbe3VBjzWyOmS0O5k8B7khpZT1ItDLCsk17WLddjQVFJD21dzfUI8D3gCYAd18EdOiGR3JsbY0FdVaUiKSr9oZF4VHuY9Gc7GJ6qvKSIioG9Wa2GguKSJpqb1hsNbPRxFp8YGafBzamrKoeKFoZYf5H29lVr8aCIpJ+2hsW04GfA+PNrBa4FbgpZVX1QNHKCC2tzlw1FhSRNNTes6FWufsUoBQY7+7nuvvqlFbWw0ws609pn3wdtxCRtPSJjQTN7LZjjAPg7j9OQU09UltjwRff20BDcwv5OdlhlyQiclCiLYs+CR6SRNHKCPsaW/jzh2osKCLpJVGL8n/pqkIEzh5dQmFerLHgheMGhV2OiMhB7b0ob5SZ/d7M6sxsi5m9YGajUl1cT1OQm835FaXMXrqZ1lY1FhSR9NHes6F+DfwGGAKcAPwWeLqzKzWzb5nZB2a22MyeNrMCMxtpZvPNrMbM/svM8oJl84P5muD18s6utzuIVkbYvLuBv9TuCrsUEZGDOnJR3n+6e3Pw+BVQ0JkVmtlQ4Gagyt1PArKJXQ1+N/ATdx8D7AC+Grzlq8COYPwnwXIZ6+Lxg8jOMp0VJSJppb1h8Qczu9PMyoO75N1BrE15sZkVd2K9OUAvM8sBCold4Hcx8Gzw+pPAlcH0FRzqcPssMNnaTsfKQAOK8qgaMUBhISJppb1h8bfAjcBc4FViF+RdAywEFnRkhe5eC/wIWEssJHYFn7PT3dtaiKwHhgbTQ4F1wXubg+UHHvm5ZjbNzBaY2YK6urqOlJR2opURlm/ew9ptaiwoIukhYViYWRbwBXcfeYxHhw50m9kAYlsLI4kd/ygCpnam+HjuPsPdq9y9qrS09Hg/LlSXVA4GoFq9okQkTSQMC3dvBR5M4jqnAB+5e527NwHPAecA/YPdUgBlQG0wXQsMAwhe7wdk9IUIwwcWMi7SRzdEEpG00d7dUHPM7HNJOlawFphkZoXB500GlhDbxfX5YJkbiN3vG+DFYJ7g9Ve8B9ywOloZ4e3VO9hZ3xh2KSIi7Q6LG4mdLttoZrvNbI+Zdeqm0e4+n9iB6neAvwQ1zAC+C9xmZjXEjkk8FrzlMWBgMH4bcGdn1tvdTAkaC76yTI0FRSR8n3gFdxt3T2prD3e/C7jriOFVHOVWre5+ALg6mevvDk4Z2o9BQWPBq04vC7scEenh2nsFt5nZF8zsn4P5YWame3CnUFaWMaUywmsr6jjQ1BJ2OSLSw7V3N9TPgLOAvw/m9wIPpaQiOShaGaFejQVFJA20Nyw+7e7TgQMA7r4DyEtZVQLA2aMHUpSXzSxdoCciIWtvWDSZWTaHbqtaCrSmrCoBID8nmwvGqbGgiISvvWHxAPA8MMjMvg+8CfwgZVXJQdHKCHV7Gnh//c6wSxGRHqy9Z0M9ZWYLiV0TYcCV7r40pZUJABeNizUWnL10M6cNHxB2OSLSQyW6rWoB8HVgDLFrIn4e179JukD/wjzOLC+meslmbr90fNjliHRbLa3OvsZm9jW0PVrY19DM3oZm9jU2s7ehhfrgtb3Ba4eWbzm4XNv7AIryc+idn01hXg6983Moys8OxnKCsdh8UdtrB5c7tGxRfg5FeTlkZ6V3f9REWxZPAk3AG8BlwATg1lQXJYeLVkb41/9ZwqL1Oxnct4BWB8dpdWhtdTx+3h332FjbfGsw7/HzgPuhz2j7zEPLEPc5h+YPe44dwuK8MaX0K8wN9w+pm9i06wC1O/djFttEh9g97Q2CMaOtT0L8/GHTwWscNh970zE/5yjrCD7i8Pk01NjSevgXeNyX+8e++IMv9/rDvtxjgXCgqX2HWc2gKC+Hwrzsw77YT+hfQGFezsGAAA6rYW9DM1v3NrJmW31s3Q3N7Gts/2nvBblZh9aXd3iY9M77eMAcHlKH5vsU5NCnIPn/Hu2TOmeY2V/c/eRgOgd4y91PT3oVSVZVVeULFnSoGW5aW7e9nvPumRt2Gcf0mVOG8NDfp/1fi9Dt2t/EhffOZUd9U9ilZJS2L/eDX6TBdNuXaPwv/ENj2XFfsm1f0LFleuVmk5WkX/mtrc7+pkNbMPWNLQeDZG8QcvWNzXFjsfn41/fFb9E0NpOo2dHEsn688I/ndqpeM1vo7lVHey3RlsXBv9Xu3pzBt5FIa8OKC3n0+io27j5AVvBLMMsgy+zgr8ZjzWcFPx8Pzmcd+iUZe/3QL9f4+ayDnxP7RXpoPP698Mzb63jszY+46YJdnDS0X8h/UultxusfsqO+ifuunkhx7zyI25qLbR0GW3MQ94Xgca/FLR8sy5Hj3vauQ5/Fx953+Dxty6Uhd8jLyTrqL+m23TrJ/HJPtqwsO7glMCgJn3cwfBoP341WH7el1TcFWxWQOCwmxvWAMmI3LNodTLu7901JVfIxUyojYZdwVLdMqeB376znnpnL+eVXdFH/sWzZfYDH3vyIyyeewOfOUPsW6Zz48CGpTZjase5PetHds929b/Do4+45cdMKCqFvQS7TLxzD6yvq+NOHW8MuJ2098MpKmluc26Jjwy5FpFPae52FyDF98awRDOlXwN0vL+eTjoH1VKu37uOZt9ZxzZnDKC8pCrsckU5RWMhxK8jN5tYpFby/biczP1BrkiPdV72C3Owsbr64IuxSRDpNYSFJ8bnTyxhVWsSPZi2nuUWdYNosrt3F79/fwFfOLWdQ34KwyxHpNIWFJEVOdha3XzKOmi17ee7d2sRv6CHunbmcfr1ymXb+6LBLETkuCgtJmqknDWZiWT/ur16he3AAf/5wG6+tqGP6RaPp10sXLUr3prCQpDEzvjt1PBt2HeBX89aEXU6o3J27X17G4L4FXH9WedjliBw3hYUk1dljSjivooSH5taw50DPvVJ51pLNvLduJ7dOqaAgNzvsckSOm8JCku72S8exo76JR974KOxSQtHc0sq9M5czqrSIz+sCPMkQCgtJulPK+vOZk4fw6BurqNvTEHY5Xe65d2up2bKX2y8ZR062/olJZtDfZEmJ2y4ZS0NzKw/NrQm7lC51oKmF+6tXMLGsH1NPGhx2OSJJo7CQlBhd2pu/rSrjqflrWLe9Puxyusyv5q1hw64DfHfqeNR4UzKJwkJS5ubJFWSZ8ZPqFWGX0iV2H2jiobk1nFdRwtljSsIuRySpFBaSMkP69eJLZ5fz/Hu1LNu0O/EburlHX1/Fjvom7tAdDSUDdXlYmNk4M3sv7rHbzG41s2IzqzazlcHzgGB5M7MHzKzGzBaZme6y043cdOFoeufn8KOZy8MuJaXq9jTw6Jsf8ZlThnByme7rIZmny8PC3Ze7+6nufipwBlAPPA/cCcxx9wpgTjAPsdu5VgSPacDDXV2zdF7/wjy+fsFoZi/dwoLV28MuJ2UefGUlDc2tfFstyCVDhb0bajLwobuvAa4gds9vgucrg+krgF96zDygv5kN6fpSpbO+fE45pX3yufvlZRnZwnzttnp+/dZa/u5TwxhV2jvsckRSIuywuAZ4OpiOuPvGYHoT0HZruKHAurj3rA/GDmNm08xsgZktqKurS1W90gmFeTncPLmCt1fv4NXlmff/5sfVy8ky45bJakEumSu0sDCzPOBy4LdHvuaxn58d+gnq7jPcvcrdq0pLS5NUpSTLNZ8axoiBhdz98jJaWzNn62LJht288P4GvnzOSCJqQS4ZLMwti8uAd9y97W45m9t2LwXPW4LxWmBY3PvKgjHpRnKzs7gtOpZlm/bw4vsbwi4nae6duYw++TncdIFakEtmCzMsruXQLiiAF4EbgukbgBfixq8PzoqaBOyK210l3chfn3ICE4b05b7q5TQ2d/8bJM1ftY25y+u46cIx9CtUC3LJbKGEhZkVAVHgubjhHwJRM1sJTAnmAV4CVgE1wCPAN7qwVEmirCzjjqnjWLd9P8+8vTbsco6Lu3PPzOVE+ubzpbPLwy5HJOVywlipu+8DBh4xto3Y2VFHLuvA9C4qTVLswrGlnDmymAfm1PC508soyg/lr+Bxm710CwvX7OAHf3MyvfLUglwyX9hnQ0kP03aDpK17G/jFH7tnC/OWVufemcsYWVLE1VVqQS49g8JCutwZIwYQrYzw89dWsWNfY9jldNh/v1vLis17+c4l48hVC3LpIfQ3XUJx+6Xj2NvYzMOvfRh2KR3S0NzCj6tXcPLQflymFuTSgygsJBRjI3246rQynvjTajbu2h92Oe321Ly11O7czx1Tx5GVpRbk0nMoLCQ0t06pAIf7q1eGXUq77G1o5sG5NZwzZiDnVejCT+lZFBYSmmHFhVw3aTi/XbiOmi17wy4noUdeX8X2fY1qQS49ksJCQjX9ojH0ys3mvlnp3cJ8694GHn1jFZedNJiJw/qHXY5Il1NYSKhKeufzD+eN4g+LN/H+up1hl3NMD82t4UBzK9+5dFzYpYiEQmEhofva+aMoLsrjnpnLwi7lqNZtr+epeWu5+owyRqsFufRQCgsJXe/8HP7xojH8sWYbb67cGnY5H/OT2Sswg1umqAW59FwKC0kL100aztD+vdLuBknLN+3h+Xdr+dLZ5Qzp1yvsckRCo7CQtJCfk823omP5S+0u/rB4U9jlHHTvzGX0zs/hpgvVglx6NoWFpI2/OW0oFYN686OZy2luCb+F+YLV25m9dAtfv2A0/Qvzwi5HJFQKC0kb2VnG7ZeOY9XWffx24fpQa3F37n55GaV98vnyOeWh1iKSDhQWklailRFOG96f+2ev4EBTS2h1zF2+hbdX7+DmyRUU5nXPNuoiyaSwkLTS1sJ88+4GnvzT6lBqaG117nl5OSMGFnLNp4YlfoNID6CwkLQzadRALhhbys9e/ZBd+5u6fP0vvF/Lsk17+LZakIscpH8JkpbumDqOXfubmPF617Ywb2xu5b5ZKzjxhL589uQhXbpukXSmsJC0dOIJ/bh84gk8/uZqtuw+0GXrffqttazfsZ87po5XC3KROAoLSVu3RcfS1NLKT1+p6ZL17Wto5qevrGTSqGLOryjpknWKdBcKC0lb5SVFXHPmMJ5+ay1rtu1L+foee/Mjtu5t5I6p4zHTVoVIPIWFpLWbL64gJ9u4b9aKlK5n+75GZry+iktPjHD68AEpXZdId6SwkLQ2qG8BXzlnJC++v4EPNuxK2XoemltDfWMzt6sFuchRKSwk7d14wWj69crl3pmpuUFS7c79/Oef1/D5M8oYM6hPStYh0t0pLCTt9euVy00XjubV5XXMW7Ut6Z9/f/UKMLhlytikf7ZIpgglLMysv5k9a2bLzGypmZ1lZsVmVm1mK4PnAcGyZmYPmFmNmS0ys9PDqFnC9aWzy4n0zeeeJLcwX7l5D797Zz3XTxrB0P5qQS5yLGFtWfw78LK7jwcmAkuBO4E57l4BzAnmAS4DKoLHNODhri9XwlaQm82tU8byztqdzF66JWmfe+/M5RTl5TD9ojFJ+0yRTNTlYWFm/YDzgccA3L3R3XcCVwBPBos9CVwZTF8B/NJj5gH9zUyX1vZAV59RxqiSIu6duYyW1uPfunhn7Q5mLdnMtPNHMaBILchFPkkYWxYjgTrgF2b2rpk9amZFQMTdNwbLbAIiwfRQYF3c+9cHY4cxs2lmtsDMFtTV1aWwfAlLTnYW375kHCs27+W/3609rs9yd+7+wzJKeufzlXNHJqlCkcwVRljkAKcDD7v7acA+Du1yAsBjO6U79NPR3We4e5W7V5WWliatWEkvl500mJOH9uPH1StoaO58C/PXVtQx/6Pt3Dx5DEX5akEukkgYYbEeWO/u84P5Z4mFx+a23UvBc9uO6Vogvk90WTAmPVBWlnHH1HHU7tzPU/PWduoz2lqQDyvuxTWfGp7kCkUyU5eHhbtvAtaZWdvVT5OBJcCLwA3B2A3AC8H0i8D1wVlRk4BdcburpAc6d0wJZ48eyINza9jb0Nzh9/9+0QaWbNzNt6PjyMvR2eMi7RHWv5RvAk+Z2SLgVOAHwA+BqJmtBKYE8wAvAauAGuAR4BtdX66kEzPjjqnj2b6vkUffWNWh97a1IB8/uA+XTzwhRRWKZJ5Qdta6+3tA1VFemnyUZR2YnvKipFs5dVh/pp44mEdeX8UXJ41gYO/8dr3vvxasY+32en7xpU+pBblIB2gbXLqt71w6jv1NLTw0t303SKpvbOaBOSs5c2QxF47TSRAiHaGwkG5rzKDeXH3GMH41bw3rd9QnXP4Xf1xN3Z4Gvjt1nFqQi3SQwkK6tVumVIDB/bNXfuJyO/Y18h+vfsiUCRHOGFHcRdWJZA6FhXRrJ/TvxQ1njeC5d9azYvOeYy738GsfsrexmTumqgW5SGcoLKTb+8aFYyjKy+FHx2hhvnHXfp7402quOq2MsRG1IBfpDIWFdHsDivKYdv4oZi3ZzMI1Oz72+v3VK8HhW9GKEKoTyQwKC8kIXzl3JCW987j7iBbmNVv28tuF6/jCpBGUDSgMsUKR7k1hIRmhKD+Hb15cwVsfbee1FYcaSd43azm9crOZftHoEKsT6f4UFpIxrj1zOMOKe3HPy8tpbXXeW7eTPyzexNfOH9Xui/ZE5OgUFpIx8nKy+HZ0HEs27ub3F36eu+/4GQMP7OEfNrwddmki3Z56M0tGufyDV/mPrTv559P/lt0Fvblr9s/p/cgcyAauuy7s8kS6LW1ZSEbJ+r//xB1zn2B3QW/Kdm7i79/7A9TXwz/9U9iliXRr2rKQzLJ2LRf5Gm598ynOXrOI/Jbmg+Mi0nkKC8ksw4dja+F0zccAAAYYSURBVNZw6x+f/ti4iHSedkNJZvn+96HwiOspCgtj4yLSaQoLySzXXQczZsCIEWAWe54xQwe3RY6TdkNJ5rnuOoWDSJJpy0JERBJSWIiISEIKCxERSUhhISIiCSksREQkIYWFiIgkpLAQEZGEFBYiIpKQxd+CMlOYWR2w5jg+ogTYmqRykkl1dYzq6hjV1TGZWNcIdy892gsZGRbHy8wWuHtV2HUcSXV1jOrqGNXVMT2tLu2GEhGRhBQWIiKSkMLi6GaEXcAxqK6OUV0do7o6pkfVpWMWIiKSkLYsREQkIYWFiIgkpLCIY2aPm9kWM1scdi1tzGyYmc01syVm9oGZ3RJ2TQBmVmBmb5nZ+0Fd/xJ2TfHMLNvM3jWz/wm7ljZmttrM/mJm75nZgrDraWNm/c3sWTNbZmZLzeyssGsCMLNxwZ9V22O3md2aBnV9K/g7v9jMnjazgrBrAjCzW4KaPkjFn5OOWcQxs/OBvcAv3f2ksOsBMLMhwBB3f8fM+gALgSvdfUnIdRlQ5O57zSwXeBO4xd3nhVlXGzO7DagC+rr7Z8OuB2JhAVS5e1pdyGVmTwJvuPujZpYHFLr7zrDrimdm2UAt8Gl3P54Lbo+3jqHE/q5Xuvt+M/sN8JK7PxFWTUFdJwHPAGcCjcDLwNfdvSZZ69CWRRx3fx3YHnYd8dx9o7u/E0zvAZYCQ8OtCjxmbzCbGzzS4peHmZUBnwEeDbuWdGdm/YDzgccA3L0x3YIiMBn4MMygiJMD9DKzHKAQ2BByPQATgPnuXu/uzcBrwFXJXIHCohsxs3LgNGB+uJXEBLt63gO2ANXunhZ1AfcDdwCtYRdyBAdmmdlCM5sWdjGBkUAd8Itgt92jZlYUdlFHcQ3wdNhFuHst8CNgLbAR2OXus8KtCoDFwHlmNtDMCoG/AoYlcwUKi27CzHoDvwNudffdYdcD4O4t7n4qUAacGWwKh8rMPgtscfeFYddyFOe6++nAZcD0YLdn2HKA04GH3f00YB9wZ7glHS7YNXY58Ns0qGUAcAWxkD0BKDKzL4RbFbj7UuBuYBaxXVDvAS3JXIfCohsIjgn8DnjK3Z8Lu54jBbst5gJTw64FOAe4PDg+8AxwsZn9KtySYoJfpbj7FuB5YvuXw7YeWB+3VfgssfBIJ5cB77j75rALAaYAH7l7nbs3Ac8BZ4dcEwDu/pi7n+Hu5wM7gBXJ/HyFRZoLDiQ/Bix19x+HXU8bMys1s/7BdC8gCiwLtypw9++5e5m7lxPbdfGKu4f+y8/MioITFAh281xCbNdBqNx9E7DOzMYFQ5OBUE+eOIprSYNdUIG1wCQzKwz+bU4mdhwxdGY2KHgeTux4xa+T+fk5yfyw7s7MngYuBErMbD1wl7s/Fm5VnAN8EfhLcHwA4P+4+0sh1gQwBHgyOEslC/iNu6fNaappKAI8H/t+IQf4tbu/HG5JB30TeCrY3bMK+HLI9RwUBGsUuDHsWgDcfb6ZPQu8AzQD75I+bT9+Z2YDgSZgerJPVNCpsyIikpB2Q4mISEIKCxERSUhhISIiCSksREQkIYWFiIgkpLAQ6SQzazmiK2rSrnw2s/J06n4soussRDpvf9DuRCTjactCJMmC+1bcE9y74i0zGxOMl5vZK2a2yMzmBFfaYmYRM3s+uDfI+2bW1j4i28weCe5PMCu4Ul4kFAoLkc7rdcRuqL+Le22Xu58MPEisCy7AT4En3f0U4CnggWD8AeA1d59IrC/TB8F4BfCQu58I7AQ+l+L/HpFj0hXcIp1kZnvdvfdRxlcDF7v7qqAJ5CZ3H2hmW4ndyKopGN/o7iVmVgeUuXtD3GeUE2v7XhHMfxfIdff/l/r/MpGP05aFSGr4MaY7oiFuugUdY5QQKSxEUuPv4p7/HEz/iVgnXIDrgDeC6TnATXDwhlL9uqpIkfbSLxWRzusV1wkY4GV3bzt9doCZLSK2dXBtMPZNYneku53Y3enaurveAswws68S24K4idhd2ETSho5ZiCRZcMyiyt23hl2LSLJoN5SIiCSkLQsREUlIWxYiIpKQwkJERBJSWIiISEIKCxERSUhhISIiCf1/9RIYRTze66sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot()\n",
    "ax1.set_ylabel('Perplexity')\n",
    "ax1.set_xlabel('Epoch')\n",
    "\n",
    "plt.plot(range(1, 10), perplex_hdp)\n",
    "plt.scatter(np.where(np.array(perplex_hdp) == min(perplex_hdp))[0][0]+1, min(perplex_hdp), color = 'r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure indicates that our algorithm achieves a best fit of the data quickly, usually after a few iterations or even only a single iteration.  Interestingly, the model does not converge on a best fit of the data at each successive iteration, which is what we expected would happen.  We think that this could be due either to incompatibilities between the functions in the perplexity module and the output of our model or issues with how our model removes topics or tables after several iterations.  Still, the model performs comparably Gensim's LDA with optimum K, with a lowest perplexity score in the mid-700s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing HDP on Simulated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have shown that our algorithm does comparably to Gensim's LDA (with optimal k) at fitting a topic model to a set of documents.   Specifically, Gensim and HDP both yield scores in the 700s on the test data.  To give the reader a frame of reference for understanding these numbers, we ran the model on some simulated data.  For this simulation, we produced a set of numbers to represent a vocabulary.  We then sampled from this vocabulary, with replacement, to produce a set of documents that represent texts with words randomly distributed across them.  Document lengths were constrained to vary from 100 to 400 words, and we produced 622 (same as real data) documents total.  There is no underlying structure in this simulated texts and any differences in how often pairs of words co-occur across these texts is  random.  Therefore, they should have a higher perplexity score than the scores we estimated above for the real data in which texts were organized around an underlying topic structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary of 1000 words  \n",
    "vocab_sim = list(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "doc_length = random.randint(100,400)\n",
    "\n",
    "docs_sim = []\n",
    "\n",
    "for j in range(622):\n",
    "    docs_sim.append([random.randint(1, 1000) for i in range(doc_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import perplexity\n",
    "\n",
    "dist_sim = []\n",
    "\n",
    "for i in range(1, 10):\n",
    "\n",
    "    # Running HDP with varying numbers of iterations\n",
    "    doc_arrays_sim, topic_idx_sim, n_kv_sim, m_k_sim = HDP_baseline.hdp(docs_sim, vocab, gamma, alpha, beta, epochs=i)\n",
    "\n",
    "    doc_dist_sim = perplexity.doc_arrays_to_doc_topic_distribution(doc_arrays_sim, topic_idx_sim)\n",
    "    word_dist_sim = perplexity.n_kv_to_word_dist(n_kv_sim, topic_idx_sim)\n",
    "    \n",
    "    # Storing distributions in list\n",
    "    dist_sim.append((doc_dist_sim, word_dist_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplex_hdp_sim = []\n",
    "for i in range(9):\n",
    "    perplex_hdp_sim.append(perplexity.perplex_func(dist_sim[i][0], dist_sim[i][1], docs_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot()\n",
    "ax1.set_ylabel('Perplexity')\n",
    "ax1.set_xlabel('Epoch')\n",
    "\n",
    "plt.plot(range(1, 10), perplex_hdp_sim)\n",
    "plt.scatter(np.where(np.array(perplex_hdp_sim) == min(perplex_hdp_sim))[0][0]+1, min(perplex_hdp_sim), color = 'r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure indicates that the model did not achieve a perplexity score below 950 for any of the iterations.  This is what we expected to find: the model finds no underlying structure in the data.  This also indicates that our HDP is working - when trained on a corpus of documents that vary meaningfully by the structure of the words they contain,  HDP fits the data well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion/conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learned several things from evaluating the results of our algorithm, both my comparing them to output of Gensim's LDA model and by making comparisons between real and simulated data.  First, we found Gensim's output to fit the data with similar accuracy to the output from our model.  This provides evidence that the algorithm works as intended.  Also, we compared the fit of this model to the relatively poor fit of the model on simulated data, in which words were randomly distributed across topics.  This gave a frame of reference through which to understand the other perplexity scores.  On random data, the model results had a perplexity score in the 1000s.  On a real corpus with an underlying topic structure, the output of both Gensim's model and our model had perplexity scores in the high 600s or 700s.\n",
    "\n",
    "Further analysis is needed to understand why our model isn't converging on a particular perplexity score.  Relatedly, our model did not converge on a consistent optimal number of topics when run on this data.  This may be due to the stochastic nature of hierarchical LDA, or to the fact that we had not trained the data for a sufficient number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "1. Yee Whye Teh, Michael I Jordan, Matthew J Beal & David M Blei (2006) Hierarchical Dirichlet Processes, Journal of the American Statistical Association, 101:476, 1566-1581, DOI: 10.1198/016214506000000302\n",
    "\n",
    "2. Blei, David M., Andrew Y. Ng, and Michael I. Jordan (2003). Latent dirichlet allocation. Journal of machine Learning research 3.Jan, 993-1022.\n",
    "\n",
    "3. Dumais, S. T., Furnas, G. W., Landauer, T. K., & Deerwester, S. (1988). Using latent semantic analysis to improve information retrieval. Proceedings of CHI'88 Conference on Human Factors in Computing Systems, 281–285.\n",
    "\n",
    "4. Khalid El-Arini (2008). Dirichlet Processes: A gentle introduction. Carnegie Mellon University, Computer Science.\n",
    "\n",
    "5. Eric P. Xing. Hierarchical Dirichlet Processes. 10-708: Probabilistic Graphical Models 10-708, Spring 2014. Scribe Notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author Contributions\n",
    "Both authors contributed equally to the development of this project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
